{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: statsmodels in /opt/homebrew/anaconda3/lib/python3.12/site-packages (0.14.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmdarima\n",
      "  Downloading pmdarima-2.0.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.4.2)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima)\n",
      "  Downloading Cython-3.0.11-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (0.14.2)\n",
      "Requirement already satisfied: urllib3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (2.2.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (69.5.1)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pmdarima) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=0.19->pmdarima) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.22->pmdarima) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\n",
      "Requirement already satisfied: six in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Downloading pmdarima-2.0.4-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Cython-3.0.11-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Cython, pmdarima\n",
      "Successfully installed Cython-3.0.11 pmdarima-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp sensor_id event_type     location\n",
      "0  2023-01-01 00:00:00  sensor_2     motion      bedroom\n",
      "1  2023-01-01 00:00:00  sensor_2  door_open      kitchen\n",
      "2  2023-01-01 03:00:00  sensor_1     motion      bedroom\n",
      "3  2023-01-01 03:00:00  sensor_1  door_open  living_room\n",
      "4  2023-01-01 04:00:00  sensor_2     motion      bedroom\n",
      "5  2023-01-01 04:00:00  sensor_1  door_open      bedroom\n",
      "6  2023-01-01 05:00:00  sensor_2  door_open      bedroom\n",
      "7  2023-01-01 06:00:00  sensor_1  door_open      kitchen\n",
      "8  2023-01-01 07:00:00  sensor_3     motion  living_room\n",
      "9  2023-01-01 08:00:00  sensor_2     motion      kitchen\n",
      "10 2023-01-01 08:00:00  sensor_3   light_on      kitchen\n",
      "11 2023-01-01 09:00:00  sensor_1   light_on      kitchen\n",
      "12 2023-01-01 10:00:00  sensor_2  door_open      bedroom\n",
      "13 2023-01-01 10:00:00  sensor_1     motion  living_room\n",
      "14 2023-01-01 10:00:00  sensor_2     motion  living_room\n",
      "15 2023-01-01 10:00:00  sensor_2   light_on  living_room\n",
      "16 2023-01-01 11:00:00  sensor_3     motion      kitchen\n",
      "17 2023-01-01 12:00:00  sensor_2  door_open  living_room\n",
      "18 2023-01-01 16:00:00  sensor_2     motion      bedroom\n",
      "19 2023-01-01 19:00:00  sensor_3     motion      kitchen\n",
      "20 2023-01-01 20:00:00  sensor_2  door_open  living_room\n",
      "21 2023-01-01 20:00:00  sensor_1  door_open  living_room\n",
      "22 2023-01-01 21:00:00  sensor_3   light_on  living_room\n",
      "23 2023-01-01 22:00:00  sensor_2   light_on  living_room\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_63971/2465197900.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  timestamps = pd.date_range(start=f\"{date} 00:00\", end=f\"{date} 23:00\", freq='H').to_pydatetime().tolist()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 가상의 센서 데이터 생성 함수\n",
    "def generate_sensor_data_for_one_day(date, num_entries):\n",
    "    timestamps = pd.date_range(start=f\"{date} 00:00\", end=f\"{date} 23:00\", freq='H').to_pydatetime().tolist()\n",
    "    sensor_data = {\n",
    "        'timestamp': np.random.choice(timestamps, size=num_entries, replace=True),\n",
    "        'sensor_id': np.random.choice(['sensor_1', 'sensor_2', 'sensor_3'], size=num_entries),\n",
    "        'event_type': np.random.choice(['motion', 'door_open', 'light_on'], size=num_entries),\n",
    "        'location': np.random.choice(['living_room', 'bedroom', 'kitchen'], size=num_entries)\n",
    "    }\n",
    "    return pd.DataFrame(sensor_data)\n",
    "\n",
    "# 데이터 생성 (2023년 1월 1일 하루 동안)\n",
    "date = \"2023-01-01\"\n",
    "data = generate_sensor_data_for_one_day(date, 24)\n",
    "\n",
    "# 타임스탬프 정렬\n",
    "data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hourly_activity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 시간대별 이벤트 발생 빈도를 시각화\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m hourly_activity\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHourly Activity\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour of the Day\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hourly_activity' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# 시간대별 이벤트 발생 빈도를 시각화\n",
    "hourly_activity.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Hourly Activity')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.show()\n",
    "\n",
    "# 시계열 모델을 이용한 패턴 예측 (ARIMA 모델)\n",
    "model = ARIMA(hourly_activity, order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# 예측 결과\n",
    "forecast = model_fit.forecast(steps=24)\n",
    "print(forecast)\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hourly_activity.index, hourly_activity, label='Observed')\n",
    "plt.plot(forecast.index, forecast, label='Forecast', color='red')\n",
    "plt.title('Hourly Activity Forecast')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Number of Events')\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/2592979658.py:8: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  timestamps = pd.date_range(start=f\"{date} 00:00\", end=f\"{date} 23:00\", freq='H').to_pydatetime().tolist()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   15\n",
      "Model:                        SARIMAX   Log Likelihood                 -16.185\n",
      "Date:                Tue, 03 Sep 2024   AIC                             36.370\n",
      "Time:                        01:09:22   BIC                             37.786\n",
      "Sample:                             0   HQIC                            36.355\n",
      "                                 - 15                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      1.6000      0.245      6.525      0.000       1.119       2.081\n",
      "sigma2         0.5067      0.306      1.653      0.098      -0.094       1.107\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.10   Jarque-Bera (JB):                 1.73\n",
      "Prob(Q):                              0.75   Prob(JB):                         0.42\n",
      "Heteroskedasticity (H):               1.00   Skew:                             0.75\n",
      "Prob(H) (two-sided):                  1.00   Kurtosis:                         2.30\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "\n",
    "# 가상의 센서 데이터 생성 함수\n",
    "def generate_sensor_data_for_one_day(date, num_entries):\n",
    "    timestamps = pd.date_range(start=f\"{date} 00:00\", end=f\"{date} 23:00\", freq='H').to_pydatetime().tolist()\n",
    "    sensor_data = {\n",
    "        'timestamp': np.random.choice(timestamps, size=num_entries, replace=True),\n",
    "        'sensor_id': np.random.choice(['sensor_1', 'sensor_2', 'sensor_3'], size=num_entries),\n",
    "        'event_type': np.random.choice(['motion', 'door_open', 'light_on'], size=num_entries),\n",
    "        'location': np.random.choice(['living_room', 'bedroom', 'kitchen'], size=num_entries)\n",
    "    }\n",
    "    return pd.DataFrame(sensor_data)\n",
    "\n",
    "# 데이터 생성 (2023년 1월 1일 하루 동안)\n",
    "date = \"2023-01-01\"\n",
    "data = generate_sensor_data_for_one_day(date, 24)\n",
    "\n",
    "# 시간대별 이벤트 발생 빈도 계산\n",
    "data['hour'] = data['timestamp'].dt.hour\n",
    "hourly_activity = data.groupby('hour').size()\n",
    "\n",
    "# 시간대별 이벤트 발생 빈도를 시각화\n",
    "hourly_activity.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Hourly Activity')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.show()\n",
    "\n",
    "# auto_arima를 사용하여 최적의 ARIMA 모델 찾기\n",
    "model = pm.auto_arima(hourly_activity, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "print(model.summary())\n",
    "\n",
    "# 예측 결과 (24시간 예측)\n",
    "forecast = model.predict(n_periods=24)\n",
    "\n",
    "# 예측 시간대를 0시부터 23시까지로 맞춤\n",
    "forecast_index = np.arange(0, 24)\n",
    "forecast_series = pd.Series(forecast, index=forecast_index)\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hourly_activity.index, hourly_activity, label='Observed')\n",
    "plt.plot(forecast_series.index, forecast_series, label='Forecast', color='red')\n",
    "plt.title('Hourly Activity Forecast')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/lib/python3.12/site-packages (74.0.0)\n",
      "Requirement already satisfied: wheel in /opt/homebrew/anaconda3/lib/python3.12/site-packages (0.44.0)\n",
      "Requirement already satisfied: Cython in /opt/homebrew/anaconda3/lib/python3.12/site-packages (3.0.11)\n",
      "Collecting pystan==2.19.1.1\n",
      "  Using cached pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Cython!=0.25.1,>=0.22 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pystan==2.19.1.1) (3.0.11)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pystan==2.19.1.1) (1.26.4)\n",
      "Building wheels for collected packages: pystan\n",
      "  Building wheel for pystan (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-7trlbap7/pystan_4adb92e55c344a979048cf92206ea898/setup.py:61: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  \u001b[31m   \u001b[0m   self.version = node.value.s\n",
      "  \u001b[31m   \u001b[0m Cython>=0.22 and NumPy are required.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pystan\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pystan\n",
      "Failed to build pystan\n",
      "\u001b[31mERROR: Could not build wheels for pystan, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting fbprophet\n",
      "  Using cached fbprophet-0.7.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (3.0.11)\n",
      "Collecting cmdstanpy==0.9.5 (from fbprophet)\n",
      "  Using cached cmdstanpy-0.9.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Using cached pystan-3.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (2.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (3.8.4)\n",
      "Collecting LunarCalendar>=0.0.9 (from fbprophet)\n",
      "  Using cached LunarCalendar-0.0.9-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting convertdate>=2.1.2 (from fbprophet)\n",
      "  Using cached convertdate-2.4.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: holidays>=0.10.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (0.54)\n",
      "Collecting setuptools-git>=1.2 (from fbprophet)\n",
      "  Using cached setuptools_git-1.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (4.66.4)\n",
      "Collecting pymeeus<=1,>=0.3.13 (from convertdate>=2.1.2->fbprophet)\n",
      "  Using cached PyMeeus-0.5.12-py3-none-any.whl\n",
      "Collecting ephem>=3.7.5.3 (from LunarCalendar>=0.0.9->fbprophet)\n",
      "  Using cached ephem-4.1.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pytz in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from LunarCalendar>=0.0.9->fbprophet) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.4->fbprophet) (2023.3)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.6 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pystan>=2.14->fbprophet) (3.9.5)\n",
      "Collecting clikit<0.7,>=0.6 (from pystan>=2.14->fbprophet)\n",
      "  Using cached clikit-0.6.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Using cached pystan-3.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached pystan-3.7.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.6.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.5.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is still looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pystan-3.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached pystan-3.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.0->fbprophet) (1.16.0)\n",
      "Using cached cmdstanpy-0.9.5-py3-none-any.whl (37 kB)\n",
      "Using cached convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "Using cached LunarCalendar-0.0.9-py2.py3-none-any.whl (18 kB)\n",
      "Using cached setuptools_git-1.2-py2.py3-none-any.whl (10 kB)\n",
      "Using cached ephem-4.1.5-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Building wheels for collected packages: fbprophet, pystan\n",
      "  Building wheel for fbprophet (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[72 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/setup.py:10: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  \u001b[31m   \u001b[0m   from pkg_resources import (\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/setup.py:19: SetuptoolsDeprecationWarning: The test command is disabled and references to it are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please remove any references to `setuptools.command.test` in all supported versions of the affected package.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2024-Nov-15, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   from setuptools.command.test import test as test_command\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py:260: UserWarning: Unknown distribution option: 'test_suite'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/fbprophet\n",
      "  \u001b[31m   \u001b[0m creating build/lib/fbprophet/stan_model\n",
      "  \u001b[31m   \u001b[0m NumExpr defaulting to 8 threads.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/setup.py\", line 122, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/__init__.py\", line 117, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 953, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 972, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py\", line 384, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 972, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 972, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/setup.py\", line 48, in run\n",
      "  \u001b[31m   \u001b[0m     build_models(target_dir)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/setup.py\", line 36, in build_models\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.models import StanBackendEnum\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/fbprophet/__init__.py\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.forecaster import Prophet\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/fbprophet/forecaster.py\", line 17, in <module>\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.make_holidays import get_holiday_names, make_holidays_df\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/fbprophet/make_holidays.py\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m     import fbprophet.hdays as hdays_part2\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/fbprophet_2c750c617e5c4fc685b558b3d81c8662/fbprophet/hdays.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     from convertdate.islamic import from_gregorian, to_gregorian\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'convertdate'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for fbprophet\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for fbprophet\n",
      "  Building wheel for pystan (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-if6jwu6z/pystan_28fe48a2322c4e38bbbba100f32ec708/setup.py:61: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  \u001b[31m   \u001b[0m   self.version = node.value.s\n",
      "  \u001b[31m   \u001b[0m Cython>=0.22 and NumPy are required.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pystan\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pystan\n",
      "Failed to build fbprophet pystan\n",
      "\u001b[31mERROR: Could not build wheels for fbprophet, pystan, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade setuptools wheel Cython\n",
    "!pip install pystan==2.19.1.1\n",
    "!pip install fbprophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Prophet in /opt/homebrew/anaconda3/lib/python3.12/site-packages (1.1.5)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (3.8.4)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays>=0.25 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (0.54)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (4.66.4)\n",
      "Requirement already satisfied: importlib-resources in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (6.4.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from cmdstanpy>=1.0.4->Prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from holidays>=0.25->Prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.4->Prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.4->Prophet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil->holidays>=0.25->Prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fbprophet\n",
      "  Using cached fbprophet-0.7.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (3.0.11)\n",
      "Collecting cmdstanpy==0.9.5 (from fbprophet)\n",
      "  Using cached cmdstanpy-0.9.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Using cached pystan-3.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (2.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (3.8.4)\n",
      "Collecting LunarCalendar>=0.0.9 (from fbprophet)\n",
      "  Using cached LunarCalendar-0.0.9-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting convertdate>=2.1.2 (from fbprophet)\n",
      "  Using cached convertdate-2.4.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: holidays>=0.10.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (0.54)\n",
      "Collecting setuptools-git>=1.2 (from fbprophet)\n",
      "  Using cached setuptools_git-1.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from fbprophet) (4.66.4)\n",
      "Collecting pymeeus<=1,>=0.3.13 (from convertdate>=2.1.2->fbprophet)\n",
      "  Using cached PyMeeus-0.5.12-py3-none-any.whl\n",
      "Collecting ephem>=3.7.5.3 (from LunarCalendar>=0.0.9->fbprophet)\n",
      "  Using cached ephem-4.1.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pytz in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from LunarCalendar>=0.0.9->fbprophet) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->fbprophet) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.4->fbprophet) (2023.3)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.6 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pystan>=2.14->fbprophet) (3.9.5)\n",
      "Collecting clikit<0.7,>=0.6 (from pystan>=2.14->fbprophet)\n",
      "  Using cached clikit-0.6.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Using cached pystan-3.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached pystan-3.7.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.6.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.5.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Using cached pystan-3.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is still looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pystan-3.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached pystan-3.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Using cached pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.0->fbprophet) (1.16.0)\n",
      "Using cached cmdstanpy-0.9.5-py3-none-any.whl (37 kB)\n",
      "Using cached convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "Using cached LunarCalendar-0.0.9-py2.py3-none-any.whl (18 kB)\n",
      "Using cached setuptools_git-1.2-py2.py3-none-any.whl (10 kB)\n",
      "Using cached ephem-4.1.5-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Building wheels for collected packages: fbprophet, pystan\n",
      "  Building wheel for fbprophet (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[72 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/setup.py:10: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  \u001b[31m   \u001b[0m   from pkg_resources import (\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/setup.py:19: SetuptoolsDeprecationWarning: The test command is disabled and references to it are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please remove any references to `setuptools.command.test` in all supported versions of the affected package.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2024-Nov-15, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   from setuptools.command.test import test as test_command\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py:260: UserWarning: Unknown distribution option: 'test_suite'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/fbprophet\n",
      "  \u001b[31m   \u001b[0m creating build/lib/fbprophet/stan_model\n",
      "  \u001b[31m   \u001b[0m NumExpr defaulting to 8 threads.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/setup.py\", line 122, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/__init__.py\", line 117, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 953, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 972, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py\", line 384, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 972, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/command/build.py\", line 135, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/dist.py\", line 950, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/anaconda3/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 972, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/setup.py\", line 48, in run\n",
      "  \u001b[31m   \u001b[0m     build_models(target_dir)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/setup.py\", line 36, in build_models\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.models import StanBackendEnum\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/fbprophet/__init__.py\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.forecaster import Prophet\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/fbprophet/forecaster.py\", line 17, in <module>\n",
      "  \u001b[31m   \u001b[0m     from fbprophet.make_holidays import get_holiday_names, make_holidays_df\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/fbprophet/make_holidays.py\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m     import fbprophet.hdays as hdays_part2\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/fbprophet_59e1aebe293c4c379b596a2869688957/fbprophet/hdays.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     from convertdate.islamic import from_gregorian, to_gregorian\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'convertdate'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for fbprophet\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for fbprophet\n",
      "  Building wheel for pystan (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/pip-install-umokr761/pystan_1b08a58989684578b098d662f3c2d054/setup.py:61: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  \u001b[31m   \u001b[0m   self.version = node.value.s\n",
      "  \u001b[31m   \u001b[0m Cython>=0.22 and NumPy are required.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pystan\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pystan\n",
      "Failed to build fbprophet pystan\n",
      "\u001b[31mERROR: Could not build wheels for fbprophet, pystan, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Prophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mProphet\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 가상의 센서 데이터 생성 함수\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_sensor_data_for_one_day\u001b[39m(date, num_entries):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Prophet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Prophet\n",
    "\n",
    "# 가상의 센서 데이터 생성 함수\n",
    "def generate_sensor_data_for_one_day(date, num_entries):\n",
    "    timestamps = pd.date_range(start=f\"{date} 00:00\", end=f\"{date} 23:00\", freq='H').to_pydatetime().tolist()\n",
    "    sensor_data = {\n",
    "        'timestamp': np.random.choice(timestamps, size=num_entries, replace=True),\n",
    "        'sensor_id': np.random.choice(['sensor_1', 'sensor_2', 'sensor_3'], size=num_entries),\n",
    "        'event_type': np.random.choice(['motion', 'door_open', 'light_on'], size=num_entries),\n",
    "        'location': np.random.choice(['living_room', 'bedroom', 'kitchen'], size=num_entries)\n",
    "    }\n",
    "    return pd.DataFrame(sensor_data)\n",
    "\n",
    "# 데이터 생성 (2023년 1월 1일 하루 동안)\n",
    "date = \"2023-01-01\"\n",
    "data = generate_sensor_data_for_one_day(date, 100)\n",
    "\n",
    "# 시간대별 이벤트 발생 빈도 계산 및 Prophet 모델에 맞는 형식으로 변환\n",
    "data['ds'] = pd.to_datetime(data['timestamp']).dt.floor('H')  # Prophet은 'ds' 열에 날짜 데이터를 필요로 함\n",
    "data['y'] = data.groupby('ds').size().reindex(pd.date_range(start=f\"{date} 00:00\", end=f\"{date} 23:00\", freq='H'), fill_value=0).values\n",
    "\n",
    "# Prophet 모델 생성 및 학습\n",
    "model = Prophet()\n",
    "model.fit(data[['ds', 'y']])\n",
    "\n",
    "# 24시간 예측\n",
    "future = model.make_future_dataframe(periods=24, freq='H')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# 예측 결과 시각화\n",
    "fig = model.plot(forecast)\n",
    "plt.title('Hourly Activity Forecast with Prophet')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Prophet in /opt/homebrew/anaconda3/lib/python3.12/site-packages (1.1.5)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (3.8.4)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays>=0.25 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (0.54)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (4.66.4)\n",
      "Requirement already satisfied: importlib-resources in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from Prophet) (6.4.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from cmdstanpy>=1.0.4->Prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from holidays>=0.25->Prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from matplotlib>=2.0.0->Prophet) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.4->Prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.4->Prophet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil->holidays>=0.25->Prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.056115456357986\n",
      "Mean Squared Error (MSE): 53.95370870543828\n",
      "Root Mean Squared Error (RMSE): 7.345318829393199\n",
      "Mean Absolute Percentage Error (MAPE): nan%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 실제 값 (테스트 데이터의 일부라고 가정)\n",
    "actual = hourly_activity[-24:]  # 최근 24시간 데이터를 실제 값으로 사용\n",
    "\n",
    "# 예측 값 (ARIMA 모델의 예측 결과)\n",
    "forecast = model_fit.forecast(steps=24)\n",
    "\n",
    "# MAE 계산\n",
    "mae = mean_absolute_error(actual, forecast)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# MSE 계산\n",
    "mse = mean_squared_error(actual, forecast)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# MAPE 계산\n",
    "mape = np.mean(np.abs((actual - forecast) / actual)) * 100\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted Values:\n",
      "24    40.703081\n",
      "25    41.808987\n",
      "26    41.438026\n",
      "27    41.562460\n",
      "28    41.520720\n",
      "29    41.534721\n",
      "30    41.530025\n",
      "31    41.531600\n",
      "32    41.531072\n",
      "33    41.531249\n",
      "34    41.531190\n",
      "35    41.531210\n",
      "36    41.531203\n",
      "37    41.531205\n",
      "38    41.531204\n",
      "39    41.531205\n",
      "40    41.531204\n",
      "41    41.531205\n",
      "42    41.531204\n",
      "43    41.531204\n",
      "44    41.531204\n",
      "45    41.531204\n",
      "46    41.531204\n",
      "47    41.531204\n",
      "Name: predicted_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ARIMA 모델 예측\n",
    "forecast = model_fit.forecast(steps=24)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(\"Forecasted Values:\")\n",
    "print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Hour  Forecasted Events\n",
      "24     0          40.703081\n",
      "25     1          41.808987\n",
      "26     2          41.438026\n",
      "27     3          41.562460\n",
      "28     4          41.520720\n",
      "29     5          41.534721\n",
      "30     6          41.530025\n",
      "31     7          41.531600\n",
      "32     8          41.531072\n",
      "33     9          41.531249\n",
      "34    10          41.531190\n",
      "35    11          41.531210\n",
      "36    12          41.531203\n",
      "37    13          41.531205\n",
      "38    14          41.531204\n",
      "39    15          41.531205\n",
      "40    16          41.531204\n",
      "41    17          41.531205\n",
      "42    18          41.531204\n",
      "43    19          41.531204\n",
      "44    20          41.531204\n",
      "45    21          41.531204\n",
      "46    22          41.531204\n",
      "47    23          41.531204\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예측 결과를 DataFrame으로 변환\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Hour': range(len(forecast)),\n",
    "    'Forecasted Events': forecast\n",
    "})\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast results saved to 'forecasted_events.csv'\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 CSV 파일로 저장\n",
    "forecast_df.to_csv('forecasted_events.csv', index=False)\n",
    "print(\"Forecast results saved to 'forecasted_events.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.4.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (74.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow)\n",
      "  Using cached optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl (236.3 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Using cached ml_dtypes-0.4.0-cp312-cp312-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 keras-3.5.0 libclang-18.1.1 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9421  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7968\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6920\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5229 \n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4435 \n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3214 \n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2086 \n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0489 \n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0130     \n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0405\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9647  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8396\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7406 \n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6016\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4566\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3442\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2669 \n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0882 \n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0904\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0625\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9342  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8134\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6963 \n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5747\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4864\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2963\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1969 \n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0959\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0389\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Predicted time differences for sensor A: [[63.47947]\n",
      " [97.36425]\n",
      " [97.36425]]\n",
      "Predicted time differences for sensor B: [[60.014565]\n",
      " [94.19873 ]\n",
      " [94.19873 ]]\n",
      "Predicted time differences for sensor C: [[59.67756]\n",
      " [95.18233]\n",
      " [95.18233]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# LSTM 모델을 구축하는 함수\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 예시 데이터프레임 생성\n",
    "data = pd.DataFrame({\n",
    "    'time_a': ['08:00', '09:15', '10:30', '11:45', '13:00'],\n",
    "    'time_b': ['08:30', '09:45', '11:00', '12:15', '13:30'],\n",
    "    'time_c': ['08:45', '10:00', '11:15', '12:30', '13:45']\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes_a'] = data['time_a'].apply(time_to_minutes)\n",
    "data['minutes_b'] = data['time_b'].apply(time_to_minutes)\n",
    "data['minutes_c'] = data['time_c'].apply(time_to_minutes)\n",
    "\n",
    "# 시간 간격 계산\n",
    "data['time_diff_a'] = data['minutes_a'].diff().fillna(0)\n",
    "data['time_diff_b'] = data['minutes_b'].diff().fillna(0)\n",
    "data['time_diff_c'] = data['minutes_c'].diff().fillna(0)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_a = MinMaxScaler()\n",
    "scaler_b = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "data_scaled_a = scaler_a.fit_transform(data[['time_diff_a']])\n",
    "data_scaled_b = scaler_b.fit_transform(data[['time_diff_b']])\n",
    "data_scaled_c = scaler_c.fit_transform(data[['time_diff_c']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 2\n",
    "\n",
    "X_a, y_a = create_sequences(data_scaled_a, SEQ_LENGTH)\n",
    "X_b, y_b = create_sequences(data_scaled_b, SEQ_LENGTH)\n",
    "X_c, y_c = create_sequences(data_scaled_c, SEQ_LENGTH)\n",
    "\n",
    "# 각 센서에 대한 모델 구축 및 학습\n",
    "model_a = build_model((SEQ_LENGTH, 1))\n",
    "model_a.fit(X_a, y_a, batch_size=1, epochs=10)\n",
    "\n",
    "model_b = build_model((SEQ_LENGTH, 1))\n",
    "model_b.fit(X_b, y_b, batch_size=1, epochs=10)\n",
    "\n",
    "model_c = build_model((SEQ_LENGTH, 1))\n",
    "model_c.fit(X_c, y_c, batch_size=1, epochs=10)\n",
    "\n",
    "# 예측\n",
    "predicted_time_diff_a = model_a.predict(X_a)\n",
    "predicted_time_diff_b = model_b.predict(X_b)\n",
    "predicted_time_diff_c = model_c.predict(X_c)\n",
    "\n",
    "# 예측 결과 역변환 (정규화된 데이터를 원래 스케일로)\n",
    "predicted_time_diff_a = scaler_a.inverse_transform(predicted_time_diff_a)\n",
    "predicted_time_diff_b = scaler_b.inverse_transform(predicted_time_diff_b)\n",
    "predicted_time_diff_c = scaler_c.inverse_transform(predicted_time_diff_c)\n",
    "\n",
    "print(\"Predicted time differences for sensor A:\", predicted_time_diff_a)\n",
    "print(\"Predicted time differences for sensor B:\", predicted_time_diff_b)\n",
    "print(\"Predicted time differences for sensor C:\", predicted_time_diff_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9859  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8730\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7713\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6313\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5176 \n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4249 \n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2626 \n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1228 \n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0384\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0629 \n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0147  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8767\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7479\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6214\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5099 \n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3858\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2638\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1531 \n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0694 \n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317    \n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9791  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8479\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7419 \n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6022 \n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4566\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3828 \n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2193 \n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1614\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0888\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x2914cc720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x296ec00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "Sensor A - MAE: 16.21153386433919 RMSE: 16.22048930166922\n",
      "Sensor B - MAE: 15.181528727213541 RMSE: 15.37631699783428\n",
      "Sensor C - MAE: 16.642178853352863 RMSE: 16.66106218516378\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# LSTM 모델을 구축하는 함수\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 예시 데이터프레임 생성\n",
    "data = pd.DataFrame({\n",
    "    'time_a': ['08:00', '09:15', '10:30', '11:45', '13:00'],\n",
    "    'time_b': ['08:30', '09:45', '11:00', '12:15', '13:30'],\n",
    "    'time_c': ['08:45', '10:00', '11:15', '12:30', '13:45']\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes_a'] = data['time_a'].apply(time_to_minutes)\n",
    "data['minutes_b'] = data['time_b'].apply(time_to_minutes)\n",
    "data['minutes_c'] = data['time_c'].apply(time_to_minutes)\n",
    "\n",
    "# 시간 간격 계산\n",
    "data['time_diff_a'] = data['minutes_a'].diff().fillna(0)\n",
    "data['time_diff_b'] = data['minutes_b'].diff().fillna(0)\n",
    "data['time_diff_c'] = data['minutes_c'].diff().fillna(0)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_a = MinMaxScaler()\n",
    "scaler_b = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "data_scaled_a = scaler_a.fit_transform(data[['time_diff_a']])\n",
    "data_scaled_b = scaler_b.fit_transform(data[['time_diff_b']])\n",
    "data_scaled_c = scaler_c.fit_transform(data[['time_diff_c']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 2\n",
    "\n",
    "X_a, y_a = create_sequences(data_scaled_a, SEQ_LENGTH)\n",
    "X_b, y_b = create_sequences(data_scaled_b, SEQ_LENGTH)\n",
    "X_c, y_c = create_sequences(data_scaled_c, SEQ_LENGTH)\n",
    "\n",
    "# 각 센서에 대한 모델 구축 및 학습\n",
    "model_a = build_model((SEQ_LENGTH, 1))\n",
    "model_a.fit(X_a, y_a, batch_size=1, epochs=10)\n",
    "\n",
    "model_b = build_model((SEQ_LENGTH, 1))\n",
    "model_b.fit(X_b, y_b, batch_size=1, epochs=10)\n",
    "\n",
    "model_c = build_model((SEQ_LENGTH, 1))\n",
    "model_c.fit(X_c, y_c, batch_size=1, epochs=10)\n",
    "\n",
    "# 예측\n",
    "predicted_time_diff_a = model_a.predict(X_a)\n",
    "predicted_time_diff_b = model_b.predict(X_b)\n",
    "predicted_time_diff_c = model_c.predict(X_c)\n",
    "\n",
    "# 예측 결과 역변환 (정규화된 데이터를 원래 스케일로)\n",
    "predicted_time_diff_a = scaler_a.inverse_transform(predicted_time_diff_a)\n",
    "predicted_time_diff_b = scaler_b.inverse_transform(predicted_time_diff_b)\n",
    "predicted_time_diff_c = scaler_c.inverse_transform(predicted_time_diff_c)\n",
    "\n",
    "# 실제값과 비교하여 정확도 평가\n",
    "true_time_diff_a = scaler_a.inverse_transform(y_a.reshape(-1, 1))\n",
    "true_time_diff_b = scaler_b.inverse_transform(y_b.reshape(-1, 1))\n",
    "true_time_diff_c = scaler_c.inverse_transform(y_c.reshape(-1, 1))\n",
    "\n",
    "mae_a = mean_absolute_error(true_time_diff_a, predicted_time_diff_a)\n",
    "rmse_a = np.sqrt(mean_squared_error(true_time_diff_a, predicted_time_diff_a))\n",
    "\n",
    "mae_b = mean_absolute_error(true_time_diff_b, predicted_time_diff_b)\n",
    "rmse_b = np.sqrt(mean_squared_error(true_time_diff_b, predicted_time_diff_b))\n",
    "\n",
    "mae_c = mean_absolute_error(true_time_diff_c, predicted_time_diff_c)\n",
    "rmse_c = np.sqrt(mean_squared_error(true_time_diff_c, predicted_time_diff_c))\n",
    "\n",
    "print(\"Sensor A - MAE:\", mae_a, \"RMSE:\", rmse_a)\n",
    "print(\"Sensor B - MAE:\", mae_b, \"RMSE:\", rmse_b)\n",
    "print(\"Sensor C - MAE:\", mae_c, \"RMSE:\", rmse_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9727  \n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8878 \n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7893 \n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7322 \n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5971\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4741\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3740 \n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1868 \n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0657\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1099\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0907\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0940 \n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0633 \n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0389 \n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0310    \n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0648\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0631 \n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0254     \n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 \n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9760\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9161\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8446\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7901 \n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6971\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9780  \n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9179\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8558\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7989\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7779 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Sensor A - MAE: 9.965352376302084 RMSE: 14.257169673228155\n",
      "Sensor B - MAE: 72.09917338689168 RMSE: 72.10139544430372\n",
      "Sensor C - MAE: 72.3441238005956 RMSE: 72.3457693832281\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 모델 A (LSTM + Dropout)\n",
    "def build_model_a(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 모델 B (Simplified LSTM)\n",
    "def build_model_b(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 모델 C (RNN + Dense)\n",
    "def build_model_c(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(30, return_sequences=False))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 예시 데이터프레임 생성\n",
    "data = pd.DataFrame({\n",
    "    'time_a': ['08:00', '09:15', '10:30', '11:45', '13:00'],\n",
    "    'time_b': ['08:30', '09:45', '11:00', '12:15', '13:30'],\n",
    "    'time_c': ['08:45', '10:00', '11:15', '12:30', '13:45']\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes_a'] = data['time_a'].apply(time_to_minutes)\n",
    "data['minutes_b'] = data['time_b'].apply(time_to_minutes)\n",
    "data['minutes_c'] = data['time_c'].apply(time_to_minutes)\n",
    "\n",
    "# 시간 간격 계산\n",
    "data['time_diff_a'] = data['minutes_a'].diff().fillna(0)\n",
    "data['time_diff_b'] = data['minutes_b'].diff().fillna(0)\n",
    "data['time_diff_c'] = data['minutes_c'].diff().fillna(0)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_a = MinMaxScaler()\n",
    "scaler_b = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "data_scaled_a = scaler_a.fit_transform(data[['time_diff_a']])\n",
    "data_scaled_b = scaler_b.fit_transform(data[['time_diff_b']])\n",
    "data_scaled_c = scaler_c.fit_transform(data[['time_diff_c']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 2\n",
    "\n",
    "X_a, y_a = create_sequences(data_scaled_a, SEQ_LENGTH)\n",
    "X_b, y_b = create_sequences(data_scaled_b, SEQ_LENGTH)\n",
    "X_c, y_c = create_sequences(data_scaled_c, SEQ_LENGTH)\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 각 센서에 대한 모델 구축 및 학습\n",
    "model_a = build_model_a((SEQ_LENGTH, 1))\n",
    "model_a.fit(X_a, y_a, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "model_b = build_model_b((SEQ_LENGTH, 1))\n",
    "model_b.fit(X_b, y_b, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "model_c = build_model_c((SEQ_LENGTH, 1))\n",
    "model_c.fit(X_c, y_c, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "# 예측\n",
    "predicted_time_diff_a = model_a.predict(X_a)\n",
    "predicted_time_diff_b = model_b.predict(X_b)\n",
    "predicted_time_diff_c = model_c.predict(X_c)\n",
    "\n",
    "# 예측 결과 역변환 (정규화된 데이터를 원래 스케일로)\n",
    "predicted_time_diff_a = scaler_a.inverse_transform(predicted_time_diff_a)\n",
    "predicted_time_diff_b = scaler_b.inverse_transform(predicted_time_diff_b)\n",
    "predicted_time_diff_c = scaler_c.inverse_transform(predicted_time_diff_c)\n",
    "\n",
    "# 실제값과 비교하여 정확도 평가\n",
    "true_time_diff_a = scaler_a.inverse_transform(y_a.reshape(-1, 1))\n",
    "true_time_diff_b = scaler_b.inverse_transform(y_b.reshape(-1, 1))\n",
    "true_time_diff_c = scaler_c.inverse_transform(y_c.reshape(-1, 1))\n",
    "\n",
    "mae_a = mean_absolute_error(true_time_diff_a, predicted_time_diff_a)\n",
    "rmse_a = np.sqrt(mean_squared_error(true_time_diff_a, predicted_time_diff_a))\n",
    "\n",
    "mae_b = mean_absolute_error(true_time_diff_b, predicted_time_diff_b)\n",
    "rmse_b = np.sqrt(mean_squared_error(true_time_diff_b, predicted_time_diff_b))\n",
    "\n",
    "mae_c = mean_absolute_error(true_time_diff_c, predicted_time_diff_c)\n",
    "rmse_c = np.sqrt(mean_squared_error(true_time_diff_c, predicted_time_diff_c))\n",
    "\n",
    "print(\"Sensor A - MAE:\", mae_a, \"RMSE:\", rmse_a)\n",
    "print(\"Sensor B - MAE:\", mae_b, \"RMSE:\", rmse_b)\n",
    "print(\"Sensor C - MAE:\", mae_c, \"RMSE:\", rmse_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9622  \n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8754 \n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8038 \n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6891 \n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5518 \n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4084 \n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3511 \n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1445\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0957\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0981\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1127 \n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1293 \n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0625 \n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0582 \n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0207  \n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9604 \n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9151 \n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8692\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8112\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0095  \n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9616\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9174\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8794\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Sensor A - MAE: 16.898944854736328 RMSE: 17.54900467781743\n",
      "Sensor B - MAE: 73.84121338526408 RMSE: 73.84130836159788\n",
      "Sensor C - MAE: 73.89467740058899 RMSE: 73.89468487116049\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 모델 A (LSTM + Dropout)\n",
    "def build_model_a(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 모델 B (Simplified LSTM)\n",
    "def build_model_b(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 모델 C (RNN + Dense)\n",
    "def build_model_c(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(30, return_sequences=False))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 예시 데이터프레임 생성\n",
    "data = pd.DataFrame({\n",
    "    'time_a': ['08:00', '09:15', '10:30', '11:45', '13:00'],\n",
    "    'time_b': ['08:30', '09:45', '11:00', '12:15', '13:30'],\n",
    "    'time_c': ['08:45', '10:00', '11:15', '12:30', '13:45']\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes_a'] = data['time_a'].apply(time_to_minutes)\n",
    "data['minutes_b'] = data['time_b'].apply(time_to_minutes)\n",
    "data['minutes_c'] = data['time_c'].apply(time_to_minutes)\n",
    "\n",
    "# 시간 간격 계산\n",
    "data['time_diff_a'] = data['minutes_a'].diff().fillna(0)\n",
    "data['time_diff_b'] = data['minutes_b'].diff().fillna(0)\n",
    "data['time_diff_c'] = data['minutes_c'].diff().fillna(0)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_a = MinMaxScaler()\n",
    "scaler_b = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "data_scaled_a = scaler_a.fit_transform(data[['time_diff_a']])\n",
    "data_scaled_b = scaler_b.fit_transform(data[['time_diff_b']])\n",
    "data_scaled_c = scaler_c.fit_transform(data[['time_diff_c']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 2\n",
    "\n",
    "X_a, y_a = create_sequences(data_scaled_a, SEQ_LENGTH)\n",
    "X_b, y_b = create_sequences(data_scaled_b, SEQ_LENGTH)\n",
    "X_c, y_c = create_sequences(data_scaled_c, SEQ_LENGTH)\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 각 센서에 대한 모델 구축 및 학습\n",
    "model_a = build_model_a((SEQ_LENGTH, 1))\n",
    "model_a.fit(X_a, y_a, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "model_b = build_model_b((SEQ_LENGTH, 1))\n",
    "model_b.fit(X_b, y_b, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "model_c = build_model_c((SEQ_LENGTH, 1))\n",
    "model_c.fit(X_c, y_c, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "# 예측\n",
    "predicted_time_diff_a = model_a.predict(X_a)\n",
    "predicted_time_diff_b = model_b.predict(X_b)\n",
    "predicted_time_diff_c = model_c.predict(X_c)\n",
    "\n",
    "# 예측 결과 역변환 (정규화된 데이터를 원래 스케일로)\n",
    "predicted_time_diff_a = scaler_a.inverse_transform(predicted_time_diff_a)\n",
    "predicted_time_diff_b = scaler_b.inverse_transform(predicted_time_diff_b)\n",
    "predicted_time_diff_c = scaler_c.inverse_transform(predicted_time_diff_c)\n",
    "\n",
    "# 실제값과 비교하여 정확도 평가\n",
    "true_time_diff_a = scaler_a.inverse_transform(y_a.reshape(-1, 1))\n",
    "true_time_diff_b = scaler_b.inverse_transform(y_b.reshape(-1, 1))\n",
    "true_time_diff_c = scaler_c.inverse_transform(y_c.reshape(-1, 1))\n",
    "\n",
    "mae_a = mean_absolute_error(true_time_diff_a, predicted_time_diff_a)\n",
    "rmse_a = np.sqrt(mean_squared_error(true_time_diff_a, predicted_time_diff_a))\n",
    "\n",
    "mae_b = mean_absolute_error(true_time_diff_b, predicted_time_diff_b)\n",
    "rmse_b = np.sqrt(mean_squared_error(true_time_diff_b, predicted_time_diff_b))\n",
    "\n",
    "mae_c = mean_absolute_error(true_time_diff_c, predicted_time_diff_c)\n",
    "rmse_c = np.sqrt(mean_squared_error(true_time_diff_c, predicted_time_diff_c))\n",
    "\n",
    "print(\"Sensor A - MAE:\", mae_a, \"RMSE:\", rmse_a)\n",
    "print(\"Sensor B - MAE:\", mae_b, \"RMSE:\", rmse_b)\n",
    "print(\"Sensor C - MAE:\", mae_c, \"RMSE:\", rmse_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9900\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9405 \n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8825 \n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8303 \n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7395 \n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6880 \n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5268\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4129\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2735 \n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1019 \n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0634 \n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0404 \n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1454\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1126 \n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1170 \n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 \n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0809 \n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0889 \n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 \n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0803 \n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0373     \n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0531     \n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0309     \n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0493\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0315\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0159    \n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0261\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Evaluation Results: ['00:56', '01:24', '01:24']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 분 단위의 시간을 HH:MM 형식으로 변환하는 함수\n",
    "def minutes_to_time(minutes):\n",
    "    hh = minutes // 60\n",
    "    mm = minutes % 60\n",
    "    return f\"{int(hh):02d}:{int(mm):02d}\"\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 모델 A (LSTM + Dropout)\n",
    "def build_model_a(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 예시 데이터프레임 생성\n",
    "data = pd.DataFrame({\n",
    "    'time_a': ['08:00', '09:15', '10:30', '11:45', '13:00'],\n",
    "    'time_b': ['08:30', '09:45', '11:00', '12:15', '13:30'],\n",
    "    'time_c': ['08:45', '10:00', '11:15', '12:30', '13:45']\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes_a'] = data['time_a'].apply(time_to_minutes)\n",
    "data['minutes_b'] = data['time_b'].apply(time_to_minutes)\n",
    "data['minutes_c'] = data['time_c'].apply(time_to_minutes)\n",
    "\n",
    "# 시간 간격 계산\n",
    "data['time_diff_a'] = data['minutes_a'].diff().fillna(0)\n",
    "data['time_diff_b'] = data['minutes_b'].diff().fillna(0)\n",
    "data['time_diff_c'] = data['minutes_c'].diff().fillna(0)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_a = MinMaxScaler()\n",
    "scaler_b = MinMaxScaler()\n",
    "scaler_c = MinMaxScaler()\n",
    "\n",
    "data_scaled_a = scaler_a.fit_transform(data[['time_diff_a']])\n",
    "data_scaled_b = scaler_b.fit_transform(data[['time_diff_b']])\n",
    "data_scaled_c = scaler_c.fit_transform(data[['time_diff_c']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 2\n",
    "\n",
    "X_a, y_a = create_sequences(data_scaled_a, SEQ_LENGTH)\n",
    "X_b, y_b = create_sequences(data_scaled_b, SEQ_LENGTH)\n",
    "X_c, y_c = create_sequences(data_scaled_c, SEQ_LENGTH)\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "model_a = build_model_a((SEQ_LENGTH, 1))\n",
    "model_a.fit(X_a, y_a, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "# 예측\n",
    "predicted_time_diff_a = model_a.predict(X_a)\n",
    "\n",
    "# 예측 결과 역변환 (정규화된 데이터를 원래 스케일로)\n",
    "predicted_time_diff_a = scaler_a.inverse_transform(predicted_time_diff_a)\n",
    "\n",
    "# 실제값과 비교하여 정확도 평가\n",
    "true_time_diff_a = scaler_a.inverse_transform(y_a.reshape(-1, 1))\n",
    "\n",
    "# 임계값 설정 (차이가 임계값보다 크면 -1 반환)\n",
    "THRESHOLD_MINUTES = 30  # 예를 들어 30분\n",
    "\n",
    "def evaluate_prediction(true_diff, predicted_diff):\n",
    "    results = []\n",
    "    for true_val, pred_val in zip(true_diff, predicted_diff):\n",
    "        time_difference = abs(true_val - pred_val)[0]\n",
    "        if time_difference > THRESHOLD_MINUTES:\n",
    "            results.append(-1)\n",
    "        else:\n",
    "            # 시간을 HH:MM 형식으로 변환\n",
    "            predicted_time = minutes_to_time(int(pred_val[0]))\n",
    "            results.append(predicted_time)\n",
    "    return results\n",
    "\n",
    "# 결과 확인\n",
    "evaluation_results = evaluate_prediction(true_time_diff_a, predicted_time_diff_a)\n",
    "print(\"Evaluation Results:\", evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7140  \n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5955\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3978 \n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3689 \n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3275\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2773 \n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2903\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3069\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1485 \n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0587 \n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0614 \n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0476\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0570 \n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0196\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071     \n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 \n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054    \n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4911e-04 \n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039     \n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032    \n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        xs.append(x)\n",
    "    return np.array(xs)\n",
    "\n",
    "# 모델 A (LSTM + Dropout)\n",
    "def build_model_a(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 데이터 준비 및 학습\n",
    "data = pd.DataFrame({\n",
    "    'time_a': ['08:00', '09:15', '10:30', '11:45', '13:00'],\n",
    "})\n",
    "data['minutes_a'] = data['time_a'].apply(time_to_minutes)\n",
    "\n",
    "SEQ_LENGTH = 2\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data['minutes_a'].values.reshape(-1, 1))\n",
    "\n",
    "X = create_sequences(data_scaled, SEQ_LENGTH)\n",
    "y = data_scaled[SEQ_LENGTH:]\n",
    "\n",
    "model = build_model_a((SEQ_LENGTH, 1))\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "model.fit(X, y, batch_size=1, epochs=50, callbacks=[early_stop])\n",
    "\n",
    "# 모델 저장\n",
    "model.save('time_prediction_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 603476.4375  \n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 572601.6250 \n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 517211.1875 \n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 615234.5625\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 544133.9375\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 450206.6875\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 562052.0625\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 508458.0312\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 528975.8750\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 553921.3125 \n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 443990.7500\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 464447.4688\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 427454.3750 \n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461025.8438\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387371.9375\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 331798.7500\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456338.9688\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337184.8750\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325443.0938\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344165.0625\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 302696.0312\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 286704.4688\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282778.0625\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336750.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284296.6875\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315464.1250\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222885.3438\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191541.9688\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247072.0781 \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 197643.0625\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201060.3125\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219482.9375\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186993.8281\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131446.7188\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128081.2031\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128523.4453\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124805.2812\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128403.6406\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85820.1484\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70965.8750\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 114642.5078\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76905.7188\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47001.9961\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72504.0703 \n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73873.8828\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49773.0742\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32879.0625\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44993.6953\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21273.4434 \n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17160.2988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "MAE: 135.7530517578125\n",
      "RMSE: 170.85710014447852\n",
      "Actual times: ['10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00']\n",
      "Predicted times: ['09:57', '09:57', '09:57', '09:57', '09:57', '09:57', '09:57']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/3964399149.py:62: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 분 단위의 시간을 HH:MM 형식으로 변환하는 함수\n",
    "def minutes_to_time(minutes):\n",
    "    hh = minutes // 60\n",
    "    mm = minutes % 60\n",
    "    return f\"{int(hh):02d}:{int(mm):02d}\"\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 데이터 준비 (예시 데이터)\n",
    "data = pd.DataFrame({\n",
    "    'time': ['08:00', '08:30', '09:15', '10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00'],\n",
    "    'event_count': [1, 2, 1, 3, 2, 1, 4, 2, 1, 3]\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes'] = data['time'].apply(time_to_minutes)\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 3  # 예: 3개의 이전 이벤트를 사용해 다음 이벤트 시각을 예측\n",
    "X, y = create_sequences(data['minutes'].values, SEQ_LENGTH)\n",
    "\n",
    "# 데이터를 (samples, timesteps, features) 형태로 reshape\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(SEQ_LENGTH, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))  # 다음 이벤트 시각 (분 단위) 예측\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, batch_size=1, epochs=50, verbose=1)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# 예측 결과를 HH:MM 형식으로 변환\n",
    "predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n",
    "actual_times = [minutes_to_time(int(actual)) for actual in y]\n",
    "\n",
    "# 성능 평가\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# 예측된 시간과 실제 시간을 출력\n",
    "print(\"Actual times:\", actual_times)\n",
    "print(\"Predicted times:\", predicted_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 607050.6875  \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 534629.1875 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512461.1250\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 489232.8750 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 599889.8125\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 466594.6875\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 490308.1875\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 439134.3125\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430187.3750\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405681.7188\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431383.6250\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360340.0312 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496337.4375 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409171.6250 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356250.3750 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338694.5000 \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356321.0625 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353877.4375 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276720.5625 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311135.5312 \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288332.5625 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207224.6094 \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271195.0625 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205394.0625 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192389.5000 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149566.3125\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136507.3906\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150905.7031 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126834.2969\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108363.1953\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73151.6016 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70921.5625\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115762.3984\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104890.5469 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77129.6172\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79068.4453 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70431.8906 \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39921.9336\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32053.2383\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46208.8594  \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21652.1797 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35085.9883\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21359.9082 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19803.0859 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13181.8311\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12507.6592\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15846.0586\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11767.9082\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12563.1074\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17021.9492\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35350.0977 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13553.9854\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12405.2363 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10510.6465 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8045.2319 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11168.1445\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10968.5625\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12002.8359\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6745.1592  \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21344.0254 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13115.0742\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10610.4990\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11061.6064\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6512.9731 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8357.5254  \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17761.9238\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14186.6855\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14353.7979\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8786.5586  \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4857.6987 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7377.3296\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12954.2920 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6641.5107 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21401.8359 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7067.0234\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20557.2812 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9768.0020 \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8696.8057 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21608.9531 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11044.9336\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7369.9419  \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16605.2129 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10255.2666\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11102.6807 \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15199.2637\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15946.3320 \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7655.9990  \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11047.6182 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11233.4648 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18058.1465 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7419.4004 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8556.7002 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18190.1758 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5614.3203\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22365.8066 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16675.7715 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17774.9961 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10030.7822\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10512.6855\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11351.2559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "MAE: 91.79139055524554\n",
      "RMSE: 103.74654503869738\n",
      "Actual times: ['10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00']\n",
      "Predicted times: ['12:12', '12:12', '12:12', '12:12', '12:12', '12:12', '12:12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/3075465843.py:63: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 분 단위의 시간을 HH:MM 형식으로 변환하는 함수\n",
    "def minutes_to_time(minutes):\n",
    "    hh = minutes // 60\n",
    "    mm = minutes % 60\n",
    "    return f\"{int(hh):02d}:{int(mm):02d}\"\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 데이터 준비 (예시 데이터)\n",
    "data = pd.DataFrame({\n",
    "    'time': ['08:00', '08:30', '09:15', '10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00'],\n",
    "    'event_count': [1, 2, 1, 3, 2, 1, 4, 2, 1, 3]\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes'] = data['time'].apply(time_to_minutes)\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 3  # 예: 3개의 이전 이벤트를 사용해 다음 이벤트 시각을 예측\n",
    "X, y = create_sequences(data['minutes'].values, SEQ_LENGTH)\n",
    "\n",
    "# 데이터를 (samples, timesteps, features) 형태로 reshape\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM 모델 구성 (모델 복잡도 증가)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(SEQ_LENGTH, 1)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))  # 다음 이벤트 시각 (분 단위) 예측\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, batch_size=1, epochs=100, verbose=1)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# 예측 결과를 HH:MM 형식으로 변환\n",
    "predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n",
    "actual_times = [minutes_to_time(int(actual)) for actual in y]\n",
    "\n",
    "# 성능 평가\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# 예측된 시간과 실제 시간을 출력\n",
    "print(\"Actual times:\", actual_times)\n",
    "print(\"Predicted times:\", predicted_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5782  \n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6223 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3531 \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3366 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5284 \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3398 \n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1778 \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0424     \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2729 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0316     \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0487 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0211 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086     \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067     \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0264     \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072     \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037     \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044     \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040     \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035     \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107     \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0073 \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025     \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050     \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046     \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025     \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043     \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0311 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0277\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0050     \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0129 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121    \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0304 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029     \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036     \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083     \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0140 \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119     \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0137 \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059     \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041     \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172     \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047     \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "MAE: 7.158124651227679\n",
      "RMSE: 8.656781101084787\n",
      "Actual times: ['10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00']\n",
      "Predicted times: ['10:02', '10:28', '11:07', '12:15', '13:06', '14:03', '15:12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/3512816699.py:69: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n",
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/3512816699.py:70: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  actual_times = [minutes_to_time(int(actual)) for actual in y]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 분 단위의 시간을 HH:MM 형식으로 변환하는 함수\n",
    "def minutes_to_time(minutes):\n",
    "    hh = minutes // 60\n",
    "    mm = minutes % 60\n",
    "    return f\"{int(hh):02d}:{int(mm):02d}\"\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 데이터 준비 (예시 데이터)\n",
    "data = pd.DataFrame({\n",
    "    'time': ['08:00', '08:30', '09:15', '10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00'],\n",
    "    'event_count': [1, 2, 1, 3, 2, 1, 4, 2, 1, 3]\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes'] = data['time'].apply(time_to_minutes)\n",
    "\n",
    "# 데이터 정규화 (StandardScaler 사용)\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[['minutes']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 3  # 시퀀스 길이 변경\n",
    "X, y = create_sequences(data_scaled, SEQ_LENGTH)\n",
    "\n",
    "# 데이터를 (samples, timesteps, features) 형태로 reshape\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM 모델 구성 (모델 복잡도 증가)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(SEQ_LENGTH, 1)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))  # 다음 이벤트 시각 (분 단위) 예측\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, batch_size=1, epochs=100, verbose=1)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# 예측 결과를 역변환하여 HH:MM 형식으로 변환\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y = scaler.inverse_transform(y.reshape(-1, 1))\n",
    "\n",
    "predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n",
    "actual_times = [minutes_to_time(int(actual)) for actual in y]\n",
    "\n",
    "# 성능 평가\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# 예측된 시간과 실제 시간을 출력\n",
    "print(\"Actual times:\", actual_times)\n",
    "print(\"Predicted times:\", predicted_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2586\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4954 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6614 \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4702     \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5160 \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0753     \n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255     \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010     \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125    \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0330 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026     \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086     \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056     \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122     \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0278 \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0302 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0052     \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032     \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0233 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099     \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0178 \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0150 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0565 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0199     \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033     \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132     \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041     \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024     \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039     \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018     \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028     \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083     \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028     \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0316 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148     \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051     \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0166 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234     \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039     \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0155 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6115e-04 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051     \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011     \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022     \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125     \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3002e-04 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086     \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010     \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0230 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0203 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0362 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180     \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0164 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 \n",
      "Model has been saved to 'time_prediction_model.keras'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 데이터 준비 (예시 데이터)\n",
    "data = pd.DataFrame({\n",
    "    'time': ['08:00', '08:30', '09:15', '10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00'],\n",
    "    'event_count': [1, 2, 1, 3, 2, 1, 4, 2, 1, 3]\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes'] = data['time'].apply(time_to_minutes)\n",
    "\n",
    "# 데이터 정규화 (StandardScaler 사용)\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[['minutes']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 3\n",
    "X, y = create_sequences(data_scaled, SEQ_LENGTH)\n",
    "\n",
    "# 데이터를 (samples, timesteps, features) 형태로 reshape\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# LSTM 모델 구성\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(SEQ_LENGTH, 1)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))  # 다음 이벤트 시각 (분 단위) 예측\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, batch_size=1, epochs=100, verbose=1)\n",
    "\n",
    "# 모델 저장 (Keras 기본 형식으로 저장)\n",
    "model.save('U-Keeper.keras')\n",
    "\n",
    "print(\"Model has been saved to 'time_prediction_model.keras'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0534  \n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 \n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087     \n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 \n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0192 \n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 \n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 \n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 \n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 \n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 \n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025     \n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032    \n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074     \n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 \n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 \n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0110 \n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 \n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 \n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 \n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 \n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0047 \n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093     \n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 \n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 \n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 \n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121     \n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 \n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0293 \n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 \n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 \n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079     \n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 \n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0181 \n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0284 \n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053     \n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057     \n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 \n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 \n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0049\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023     \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "MAE: 3.2386910574776784\n",
      "RMSE: 4.497880517486081\n",
      "Actual times: ['10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00']\n",
      "Predicted times: ['10:10', '10:31', '10:58', '12:00', '12:57', '13:54', '14:58']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/586437796.py:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n",
      "/var/folders/dg/2hn16bfj6rx7h3ngyfcfwdpw0000gn/T/ipykernel_82719/586437796.py:62: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  actual_times = [minutes_to_time(int(actual)) for actual in y]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 시간 데이터를 분 단위로 변환하는 함수\n",
    "def time_to_minutes(time_str):\n",
    "    hh, mm = map(int, time_str.split(':'))\n",
    "    return hh * 60 + mm\n",
    "\n",
    "# 분 단위의 시간을 HH:MM 형식으로 변환하는 함수\n",
    "def minutes_to_time(minutes):\n",
    "    hh = minutes // 60\n",
    "    mm = minutes % 60\n",
    "    return f\"{int(hh):02d}:{int(mm):02d}\"\n",
    "\n",
    "# 시퀀스를 생성하는 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('U-Keeper.keras')\n",
    "\n",
    "# 데이터 준비 (예시 데이터 - 새로운 데이터 또는 기존 데이터)\n",
    "data = pd.DataFrame({\n",
    "    'time': ['08:00', '08:30', '09:15', '10:00', '10:30', '11:00', '12:00', '13:00', '14:00', '15:00'],\n",
    "    'event_count': [1, 2, 1, 3, 2, 1, 4, 2, 1, 3]\n",
    "})\n",
    "\n",
    "# 시간을 분 단위로 변환\n",
    "data['minutes'] = data['time'].apply(time_to_minutes)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[['minutes']])\n",
    "\n",
    "# LSTM 모델을 위한 시퀀스 생성\n",
    "SEQ_LENGTH = 3\n",
    "X, y = create_sequences(data_scaled, SEQ_LENGTH)\n",
    "\n",
    "# 데이터를 (samples, timesteps, features) 형태로 reshape\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 추가 학습 (필요할 경우)\n",
    "model.fit(X, y, batch_size=1, epochs=50, verbose=1)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# 예측 결과를 역변환하여 HH:MM 형식으로 변환\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y = scaler.inverse_transform(y.reshape(-1, 1))\n",
    "\n",
    "predicted_times = [minutes_to_time(int(pred)) for pred in predictions]\n",
    "actual_times = [minutes_to_time(int(actual)) for actual in y]\n",
    "\n",
    "# 성능 평가\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# 예측된 시간과 실제 시간을 출력\n",
    "print(\"Actual times:\", actual_times)\n",
    "print(\"Predicted times:\", predicted_times)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
